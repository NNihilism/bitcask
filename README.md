# 项目介绍
该项目主要使用***Go***语言实现一个基于***batcask***的小型数据库。提供数据的增删查改功能，能够定期对归档文件进行整理。
## 使用说明
### C/S模式
##### 服务端的运行
进入目录文件
```
cd cmd/server
```
使用默认配置开启服务端
```
go run main.go
```
##### 客户端的运行
进入目录文件
```
cd cmd/client
```
使用默认配置开启客户端
```
go run main.go
```
### 代码内嵌(?)
参考examples下的代码
### 可提供功能
#### 数据操作
1. String
    - Set 插入/更新单条数据
    - Delete 删除数据
    - Get 获取数据
    - SetEX 插入有时效性的数据
    - SetNX 插入不存在的数据，key已存在时操作失败
    - MSet 同时插入多条记录
    - MSetNX
    - Append 在指定key对应的value的末尾添加数据，若key不存在则等同于Set
    - StrLen 返回指定key对应value的长度
    - Count 返回合法的记录条数
2. 其他
#### 其他
- 文件定期归档
- 数据的crc校验
## 实现思路
### 数据存储
#### 存储类型
**string** **list** **map** **set** **zset**
#### 磁盘存储
使用文件进行数据的存储，需要注意的是，由于可能会有多个用户同时进行数据库的操作，因此需要设置文件锁来进行并发处理。【好像又不用】  
不同的数据类型需要存储在不同的*logFile*中
将LogEntry记录到磁盘文件中时，使用了variant算法来存储entry的k/v长度，能以较小的字节存储较小的数字（自然数？）。
#### 内存存储
内存中存储的主要是一个前缀树，用来加速对记录的查找操作。分为***KeyValueMemMode***以及***KeyOnlyMemModel***两种模式，在第一个模式下，根据*key*能够直接读取到*value*，而使用后者时，只能根据*key*获取到对应的*logFileId*以及相应的*offset*,需要在磁盘中找到对应的*logFile*并读取*value*。
##### String
索引树中存储的节点格式如:  
- key----value  
##### List
由于List为双向链表，所以一颗索引树中存储了两种不同的节点。  
- Key---[LSeq, Rseq]用于维护Key对应列表的左右索引.  
- Seq+Key---Val,用于维护Key对应的列表元素以及该元素所在的索引.  
上述两种操作都会引发LogEntry的写入操作，且不区分写入的文件，即都会记录在log.List.xxxx文件中。
##### Hash
Hash与List相似，不同的Key存储在不同的索引树上，写入磁盘文件时，Key格式为Key+field以此区分不同的Key以及不同的field。
##### Set
去重：
- 对于一个索引树，树上的所有key本来就是唯一的，因此，如果不同的集合使用不同的索引树来维护，那么无需可以去重，只需要给集合的每个元素确定唯一的key即可，这里使用的是hash算法来生成唯一的key。
- 而在logfile中，每个entry写入时的key为其本身的key,而不是使用hash算法生成的key(可能是为了减少存储空间吧)，即不同的记录在磁盘文件中只需要区分所在的索引树即可，而不像Hash一样，还需要区分对应的field
- ##### ZSet
1 内存中同时维护索引树和跳表，磁盘中维护logfile.  
2 索引树中，key为member经过hash后的sum, value为member, 跟score无关  
3 跳表用来维护所需同一个key中的所有sum(hash后的member)和对应的score，方便获取指定范围以及排名等  


- 需要注意的是，删除操作时，参数没有score，因此在写入logentry时，其key-value与添加操作时写入的logentry的key-value不同，哪怕他们是对同一个member进行操作。写入操作时，logentry的key和value分别为key+score, member，这是因为在初始化索引时需要key,member,score等信息。删除操作时，key,value分别为key和sum(hash后的member),在建立索引时，遍历到该logentry,即可根据sum在索引树和跳表中删除之前建立的节点。
- zset的实现中，索引树有必要存在吗？ 好像没有...

### 垃圾回收
discard中需要维护已使用以及没使用的空间。有点像文件系统中的空闲表法

### tcp传输中的粘包问题
#### 产生条件
1. 发送端开启Nagle算法，导致多个数据整合在一起发出
2. 接收端收到数据后，应用层没来得及处理，导致缓冲区数据粘在一起
#### 如何解决
1. 发送端关闭了Nagle算法(如何在golang中开启这玩意我都不知道。。。)
2. 由于客户端与服务端之间的工作模式为：客户端发送命令----服务端接收命令----服务端执行命令----服务端返回结果----客户端接收结果。客户端在发送命令至接收结果之间将阻塞，不会写入新的命令，因此对于对于客户端，不存在同时发送两条命令的情况。对于服务端，其缓冲区内的数据也必定为同一条命令的，即服务端从接收命令直至返回结果前，其缓冲区内的数据都必定为同一条命令的，因此也不会出现粘包问题。那服务端唯一需要处理的，就是保证能将缓冲区内的数据给读完，即客户端发送消息时，可能存在部分数据包因为网络阻塞的原因，没有及时达到服务端，那服务端需要对此进行处理，如继续读取直至读完或者报错。
3. 规定了传输数据的格式为 [消息头+消息体]，其中消息头指明了消息体的长度，根据该长度创建[]byte来获取消息体，若所读消息体长度没有达到消息头声明的大小，那就继续重读或者直接报错？

## Bitcask模型
### 介绍
bitcask架构就像一个巨大的hashmap，在内存中建立一个hash索引，key是对应数据的key,value是数据存放的具体位置（哪个文件以及对应的偏移量），这样做的好处是查询单条数据很快，但范围查询很慢，因为hash不支持范围查询，查多少数据就要发起多少次IO(这也是为什么项目中使用的是前缀树而不是hash的原因）。  
一个数据在内存中可以有不同的表现形式，如字符串、链表、hash、集合，但是他们持久化存储的方式都差不多。我们要保证的只有两点：
 - 取出来的东西和存进去时是相同的
 - 使用尽可能少的磁盘空间表示更多的数据

### 优势
#### 容易备份
Mysql中，除了保存在磁盘上的真正的数据文件外，还有bin log用于主从复制以及备份还原，而bitcask的日志文件logfile本身就是数据文件，备份起来很简单，只需把目录的所有文件拷贝一份至新的服务器重新建立索引即可。

#### 采用文件末尾追加的方式实现写操作
无论是新增删除还是修改，logfile的所有记录都是采用日志append的方式在末尾追加，速度比随机写入快。

#### 读操作
因为在内存中维护了一张索引表，能够使用O(1)的时间获取到数据的位置以及值。

#### 内存限制
与同为k-v数据库的Redis相比，单机redis的限制是存储的所有数据不能大于内存本身，而bitcask的限制是存储的所有索引(key)不能大于内存本身。可以理解为在数据量很大时，稍微损失一点速度，换取更大的容量。

### 可扩展方向
#### 单机模式的限制
目前的bitcask存储模型是单机模式，但存储空间是有上限的，因此可以设计一个集群模式，不同的实例存储不同的数据，使用一致性哈希算法来保证每次查询的key落在相同的实例上，即实现分库分表。
